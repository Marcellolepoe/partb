{
  "module": "CLK Module 2: Laws and Technology - Module 4: Blockchain & Artificial Intelligence",
  "questions": [
    {
      "id": "CLK-LT-M4-Q001",
      "question": "What problem was blockchain originally designed to solve, according to the notes?",
      "options": {
        "A": "Argues that the need to speed up database queries in traditional banks.",
        "B": "Maintains that the double-spend problem: preventing a digital token from being spent twice before a central ledger updates.",
        "C": "Contends that the challenge of encrypting handwritten signatures.",
        "D": "Posits that the requirement that all payments must involve a physical intermediary."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "Blockchain architecture emerged to address the double-spend problem—ensuring that a digital balance cannot be spent twice without detection. Traditional solutions rely on trusted intermediaries (banks, escrow platforms) to maintain authoritative ledgers. Blockchain proposes a distributed ledger that uses cryptography and consensus to achieve the same assurance without a single trusted third party.",
        "incorrect": {
          "A": "Performance optimisation was not the primary motivation; the focus was on trust and integrity without central intermediaries.",
          "B": "This is the correct answer.",
          "C": "Digital signatures are part of the solution, but the problem to solve was double spending, not handwriting encryption.",
          "D": "Physical intermediaries were already avoidable (e.g., banks); the issue was trust in digital settings."
        },
        "reference": "Blockchain Notes - Designed to Solve Double-Spend Problem; Avoid Reliance on Trusted Intermediary"
      }
    },
    {
      "id": "CLK-LT-M4-Q002",
      "question": "Why do we traditionally trust banks to prevent double spending, and how does blockchain offer a different trust model?",
      "options": {
        "A": "Argues that banks rely on identical technology to blockchains, so there is no difference.",
        "B": "Maintains that banks are unregulated, so users simply hope for the best blockchain relies on government guarantees.",
        "C": "Contends that banks are trusted because of legal regulation and reputational incentives blockchain instead proposes trusting the code and distributed consensus rather than an institutional intermediary.",
        "D": "Posits that banks and blockchains both operate without any regulatory oversight."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "Lessig's modalities explain trust in banks: legal regulation, reputational stakes, and market incentives keep banks reliable. Blockchain shifts reliance from institutional oversight to code—cryptographic hashing, consensus mechanisms, and transparent ledgers eliminate the need to trust a single intermediary. Users trust the protocol rather than the institution.",
        "incorrect": {
          "A": "Banks use centralised databases, not decentralised consensus.",
          "B": "Banks are heavily regulated; blockchains typically operate without government guarantees.",
          "C": "This is the correct answer.",
          "D": "Banks are subject to regulation; blockchains operate in varying legal environments."
        },
        "reference": "Trust Models - Banks Rely on Law/Reputation; Blockchain Relies on Code and Consensus"
      }
    },
    {
      "id": "CLK-LT-M4-Q003",
      "question": "What role do cryptographic hashes play in blockchain security?",
      "options": {
        "A": "Argues that they create a fixed-size digital fingerprint of block contents, making any alteration detectable because even a minor change produces a vastly different hash.",
        "B": "Maintains that they encrypt transactions so that no one can ever read them, even authorised users.",
        "C": "Contends that they randomly delete data from the ledger to preserve storage space.",
        "D": "Posits that they are optional cosmetic features with no security function."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "Cryptographic hashes generate deterministic, fixed-length outputs that change dramatically with any alteration in input data. Blockchains store the previous block's hash in each block. If a malicious actor modifies a transaction, the hash chain breaks, revealing tampering. Hashes therefore act as tamper-evident seals rather than encryption mechanisms.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "Blockchain transactions are typically public; hashes provide integrity, not confidentiality.",
          "C": "Hashing does not delete data; it verifies consistency.",
          "D": "Hashes are fundamental to blockchain immutability."
        },
        "reference": "Hashing in Blockchain - Fixed-Length Fingerprint; Tamper-Evident Seal Linking Blocks"
      }
    },
    {
      "id": "CLK-LT-M4-Q004",
      "question": "Why is including the previous block's hash in each block critical for blockchain immutability?",
      "options": {
        "A": "Argues that it allows miners to reorder blocks arbitrarily without consequences.",
        "B": "Maintains that it enables the blockchain to run without consensus mechanisms.",
        "C": "Contends that it reduces the size of the ledger by compressing data.",
        "D": "Posits that it chains blocks together so that altering one block requires recomputing all subsequent hashes, making tampering computationally prohibitive unless an attacker controls the consensus process."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "Linking blocks via hashes means that any change to an earlier block cascades forward—all later hashes become invalid. An attacker must redo the proof-of-work (or equivalent consensus requirements) for that block and every block after it, and then overtake the honest chain. This design underpins the practical immutability of well-secured blockchains.",
        "incorrect": {
          "A": "The chaining constrains reordering—it does not facilitate it.",
          "B": "Consensus remains necessary; hash chaining complements it.",
          "C": "Hash links do not compress data; they ensure integrity.",
          "D": "This is the correct answer."
        },
        "reference": "Chaining Blocks - Previous Hash Ensures Tamper Resistance; Requires Recomputing Subsequent Blocks"
      }
    },
    {
      "id": "CLK-LT-M4-Q005",
      "question": "How do Proof of Work (PoW) and Proof of Stake (PoS) differ as consensus mechanisms?",
      "options": {
        "A": "Argues that poW requires no computation, while PoS requires solving hash puzzles.",
        "B": "Maintains that poW relies on miners solving computational puzzles, whereas PoS relies on validators' ownership stakes to secure the network.",
        "C": "Contends that poW and PoS are identical mechanisms with different names.",
        "D": "Posits that poS eliminates the need for any consensus at all."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "In PoW systems (e.g., Bitcoin), miners expend computational resources to solve hash puzzles, winning the right to append blocks. PoS systems (e.g., some modern chains) select validators based on the amount of cryptocurrency they stake, aligning incentives through economic exposure rather than hash power. Both aim to deter malicious actors, but through different resource commitments.",
        "incorrect": {
          "A": "PoW is computationally intensive; PoS is comparatively energy-efficient.",
          "B": "This is the correct answer.",
          "C": "They differ fundamentally in resource requirements and incentives.",
          "D": "PoS still involves consensus protocols to agree on the ledger state."
        },
        "reference": "Consensus Mechanisms - PoW Uses Computational Work; PoS Uses Economic Stake"
      }
    },
    {
      "id": "CLK-LT-M4-Q006",
      "question": "What limitations to blockchain tamper-resistance do the notes highlight?",
      "options": {
        "A": "Argues that blockchains are mathematically impossible to attack under any circumstance.",
        "B": "Maintains that tamper-resistance fails whenever honest nodes are in the majority.",
        "C": "Contends that tamper-resistance is probabilistic—attacks remain possible if, for example, an attacker controls >50% of hash power, puzzles are too easy, few blocks exist, or sheer luck favours the attacker.",
        "D": "Posits that tamper-resistance requires physical possession of all private keys."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "The notes caution that blockchain security is not absolute. If attackers control majority hash power (a 51% attack), if the network is small, puzzles are trivial, or randomness favours the attacker, they might outpace honest nodes. Thus, immutability is practical rather than guaranteed.",
        "incorrect": {
          "A": "Absolute security is not claimed; the notes emphasise probabilistic resistance.",
          "B": "Honest majority strengthens security; tampering becomes difficult, not easier.",
          "C": "This is the correct answer.",
          "D": "Private keys govern transaction signing, not consensus tamper-resistance."
        },
        "reference": "Limitations - Blockchain Security Is Probabilistic; Vulnerable to 51% Attacks, Weak Networks, Lucky Adversaries"
      }
    },
    {
      "id": "CLK-LT-M4-Q007",
      "question": "Beyond recording cryptocurrency transactions, what other uses does the notes identify for blockchain ledgers?",
      "options": {
        "A": "Argues that storing legal or economic rights (tokens/ICOs), linking to real-world assets (tokenisation), property records, and digital art (NFTs), illustrating blockchain's potential for trusted data registries beyond currency.",
        "B": "Maintains that only cryptocurrency transactions can be recorded on blockchain.",
        "C": "Contends that only storing random numbers for entertainment purposes.",
        "D": "Posits that running traditional relational databases with faster SQL queries."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "The notes emphasise that blockchain can underpin various registries—tokenised securities, off-chain asset references, land registries, and NFTs. The technology offers tamper-evident storage for diverse data, extending beyond purely monetary applications.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "The notes specifically list multiple non-currency uses.",
          "C": "Random numbers are not the focus of blockchain utility.",
          "D": "Blockchains are not optimised for SQL-style relational queries."
        },
        "reference": "Broader Blockchain Uses - Tokens, Tokenised Assets, Property Records, NFTs"
      }
    },
    {
      "id": "CLK-LT-M4-Q008",
      "question": "How did Bybit v Ho Kai Xin characterise cryptoassets under Singapore law?",
      "options": {
        "A": "Argues that as physical choses in possession identical to cash.",
        "B": "Maintains that as illegal instruments incapable of legal recognition.",
        "C": "Contends that as mere contractual expectations with no proprietary status.",
        "D": "Posits that as an incorporeal right of property recognisable by common law as a thing in action, enforceable in court."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "The High Court concluded that holders of cryptoassets possess an incorporeal property right—a thing in action—capable of enforcement. Although intangible and mutable, cryptoassets can be defined and identified, satisfying the Ainsworth criteria for property. This recognition aligns legal treatment with societal acceptance of crypto value.",
        "incorrect": {
          "A": "Cryptoassets are not physical choses in possession.",
          "B": "The decision affirmed, rather than denied, legal recognition.",
          "C": "The Court recognised proprietary status, not merely contractual claims.",
          "D": "This is the correct answer."
        },
        "reference": "Bybit v Ho Kai Xin (2023) - Cryptoassets Recognised as Property (Thing in Action)"
      }
    },
    {
      "id": "CLK-LT-M4-Q009",
      "question": "What analogy did the Court use in Bybit v Ho Kai Xin to explain the nature of cryptoassets?",
      "options": {
        "A": "Argues that cryptoassets are identical to physical gold bars stored in a vault.",
        "B": "Maintains that like naming a river even though its water constantly changes, cryptoassets can still be defined and identified despite their intangible, evolving nature, supporting proprietary recognition.",
        "C": "Contends that cryptoassets are best viewed as mere data entries with no analogies available.",
        "D": "Posits that cryptoassets should be treated as government-issued legal tender."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "The Court acknowledged that while cryptoassets are not physical, they can still be identified and valued. The river analogy conveys that changeability does not preclude legal recognition. This reasoning aligns crypto with other socially constructed assets like money, whose value stems from collective acceptance.",
        "incorrect": {
          "A": "The Court did not equate crypto with physical bullion.",
          "B": "This is the correct answer.",
          "C": "The Court deliberately used analogies to explain legal comprehension.",
          "D": "Crypto remains distinct from state-issued currency."
        },
        "reference": "River Analogy - Explains Identifiability of Changing Cryptoassets; Supports Property Status"
      }
    },
    {
      "id": "CLK-LT-M4-Q010",
      "question": "What broader question does the Court's reasoning in Bybit v Ho Kai Xin raise about law and technology?",
      "options": {
        "A": "Argues that whether courts should ignore societal adoption when classifying new assets.",
        "B": "Maintains that whether blockchain should be outlawed entirely.",
        "C": "Contends that whether the Court is recognising a pre-existing societal act of mutual faith in cryptoassets or effectively creating one—highlighting the interplay between legal recognition and social acceptance.",
        "D": "Posits that whether cryptoassets can replace all forms of property law."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "The notes observe that the Court's reasoning prompts reflection: is the judiciary merely acknowledging societal belief in crypto (akin to money's value through mutual faith) or is it helping to create legitimacy by conferring property status? This underscores the feedback loop between technological adoption and legal classification.",
        "incorrect": {
          "A": "The Court did not suggest ignoring social adoption; it factored it in.",
          "B": "Outlawing blockchain was not under consideration.",
          "C": "This is the correct answer.",
          "D": "Recognising crypto as property does not replace the entirety of property law."
        },
        "reference": "Bybit Reasoning - Raises Question Whether Law Recognises or Creates Mutual Faith in Cryptoassets"
      }
    },
    {
      "id": "CLK-LT-M4-Q011",
      "question": "What does it mean that blockchain operates on a peer-to-peer distributed network?",
      "options": {
        "A": "Argues that each participant holds a copy of the ledger, eliminating a single point of control or failure and enhancing resilience against tampering or outages.",
        "B": "Maintains that a single central server stores the ledger and all nodes query it.",
        "C": "Contends that only trusted financial institutions may participate in the network.",
        "D": "Posits that nodes cannot communicate directly and must route through an intermediary."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "In a decentralised peer-to-peer network, every node maintains the ledger. This redundancy means no single node can corrupt the history without consensus, and the system can continue operating even if some nodes go offline, supporting blockchain's trustless design.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "Centralised storage would reintroduce single-point failure risk.",
          "C": "Public blockchains allow broad participation; private versions still replicate ledgers across authorised nodes.",
          "D": "Peer-to-peer means direct communication without intermediaries."
        },
        "reference": "Blockchain Architecture - Peer-to-Peer Distributed Ledger Prevents Single Point of Control"
      }
    },
    {
      "id": "CLK-LT-M4-Q012",
      "question": "What is a nonce in the Proof of Work process?",
      "options": {
        "A": "Argues that a permanent encryption key shared among miners.",
        "B": "Maintains that a regulatory licence required to join the network.",
        "C": "Contends that a list of pending transactions awaiting confirmation.",
        "D": "Posits that a value miners vary to produce a hash meeting difficulty criteria (e g."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "In PoW, miners repeatedly modify a nonce—an arbitrary number—to generate a block hash that satisfies the network's difficulty target. Finding such a nonce proves computational effort, securing consensus.",
        "incorrect": {
          "A": "Nonces are ephemeral and vary per attempt; they are not shared encryption keys.",
          "B": "Participation typically requires no licence; nonce is a technical parameter.",
          "C": "Pending transactions form the mempool; they are distinct from the nonce.",
          "D": "This is the correct answer."
        },
        "reference": "PoW Mechanics - Nonce Adjusted to Produce Hash Meeting Difficulty Requirement"
      }
    },
    {
      "id": "CLK-LT-M4-Q013",
      "question": "Why must an attacker present the longest blockchain to succeed in a PoW attack?",
      "options": {
        "A": "Argues that because blockchain nodes prefer the chain with the fewest transactions.",
        "B": "Maintains that because honest nodes automatically discard shorter chains and adopt the chain with the most cumulative work, so an attacker must outpace honest mining to make its tampered chain authoritative.",
        "C": "Contends that because consensus is determined by government regulators.",
        "D": "Posits that because transaction fees are higher on shorter chains."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "PoW consensus follows the chain with the greatest accumulated work (often expressed as the longest valid chain). For an attacker to rewrite history, they must mine blocks faster than honest participants to produce a chain that the network will accept, making such attacks resource-intensive.",
        "incorrect": {
          "A": "Chain selection depends on work, not transaction count.",
          "B": "This is the correct answer.",
          "C": "Consensus emerges algorithmically, not by regulatory decree.",
          "D": "Transaction fees do not determine chain validity."
        },
        "reference": "Consensus Rule - Longest/Most-Work Chain Prevails; Attacker Must Outpace Honest Nodes"
      }
    },
    {
      "id": "CLK-LT-M4-Q014",
      "question": "What does the notes' observation that 'blocks are nothing special, just packets of data' convey?",
      "options": {
        "A": "Argues that that blockchain is technologically identical to standard databases without any structural differences.",
        "B": "Maintains that that block contents are meaningless placeholders with no real information.",
        "C": "Contends that that the novelty lies not in the data itself but in how blocks are hashed, chained, and validated via consensus—ordinary data structures made tamper-evident and distributed.",
        "D": "Posits that that blockchain is primarily a compression algorithm."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "The data stored in blocks may resemble conventional records. What differentiates blockchain is the surrounding architecture—hashing, chaining, peer distribution, and consensus—which collectively provide new trust properties. The remark demystifies blockchain by highlighting that familiar data structures, combined with novel governance mechanisms, deliver its promise.",
        "incorrect": {
          "A": "Blockchain employs distinctive integrity and consensus mechanisms absent in standard databases.",
          "B": "Blocks hold meaningful transaction or state data.",
          "C": "This is the correct answer.",
          "D": "Compression is not the primary function."
        },
        "reference": "Blocks as Data Packets - Architecture (Hashing, Chaining, Consensus) Provides Innovation"
      }
    },
    {
      "id": "CLK-LT-M4-Q015",
      "question": "Why is blockchain security described as 'wasteful, but better alternatives are elusive'?",
      "options": {
        "A": "Argues that because mechanisms like PoW consume significant energy/computation to secure consensus, yet no widely adopted alternative provides the same trustless assurance at scale.",
        "B": "Maintains that because blockchain intentionally discards most transactions to maintain scarcity.",
        "C": "Contends that because blockchains generate waste data that must be deleted daily.",
        "D": "Posits that because users must pay fees even when no transactions occur."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "PoW requires substantial computational effort, often criticised as wasteful energy expenditure. However, this expenditure underpins security by making attacks costly. Despite research into more efficient models, a universally accepted substitute that maintains decentralised trust at scale has not emerged, hence the pragmatic acceptance of PoW's inefficiency in key systems like Bitcoin.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "Transactions are not discarded to create scarcity; mining secures the ledger.",
          "C": "Blockchain data is typically preserved, not discarded daily.",
          "D": "Fees relate to resource usage; the critique focuses on energy consumption, not fee structure."
        },
        "reference": "PoW Trade-offs - Energy Intensive Yet Trusted; Better Alternatives Still Emerging"
      }
    },
    {
      "id": "CLK-LT-M4-Q016",
      "question": "What are the two major categories of AI identified in the notes?",
      "options": {
        "A": "Argues that quantum AI and analogue AI.",
        "B": "Maintains that hardware AI and software AI.",
        "C": "Contends that commercial AI and military AI.",
        "D": "Posits that rules-based ('symbolic') AI and machine learning ('statistical') AI."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "The notes contrast rules-based/symbolic AI—expert systems relying on explicit logic—with machine-learning/statistical AI, which derives patterns from data. Modern advances largely stem from the latter, addressing limitations of hand-coded rules.",
        "incorrect": {
          "A": "Quantum/analogue categories were not identified in the notes.",
          "B": "Hardware vs software is not the categorisation used.",
          "C": "Use cases (commercial vs military) differ from technical paradigms.",
          "D": "This is the correct answer."
        },
        "reference": "AI Types - Symbolic (Rules-Based) vs Statistical (Machine Learning)"
      }
    },
    {
      "id": "CLK-LT-M4-Q017",
      "question": "What limitation of rules-based (symbolic) AI do the notes highlight?",
      "options": {
        "A": "Argues that they can easily adapt to complex, evolving tasks without human input.",
        "B": "Maintains that they struggle with complex domains (like Go or law) because specifying every rule is costly and inflexible, prompting a shift toward data-driven machine learning.",
        "C": "Contends that they cannot be used for any deterministic tasks.",
        "D": "Posits that they require neural networks to operate."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "Symbolic systems excel when rules are stable and enumerated, but real-world domains often involve nuanced, evolving patterns. Capturing this exhaustively in hand-crafted rules is impractical, motivating machine-learning approaches that learn from examples rather than explicit instructions.",
        "incorrect": {
          "A": "Symbolic systems require manual maintenance; adaptability is limited.",
          "B": "This is the correct answer.",
          "C": "They perform well in deterministic domains; the issue is complexity, not determinism.",
          "D": "Neural networks belong to machine learning, not symbolic AI."
        },
        "reference": "Limitations of Symbolic AI - Difficulty Handling Complex, Evolving Domains; Drives Move to ML"
      }
    },
    {
      "id": "CLK-LT-M4-Q018",
      "question": "Outline the basic pipeline for supervised machine learning described in the notes.",
      "options": {
        "A": "Argues that structured dataset → raw data → learning algorithm → hypothesis.",
        "B": "Maintains that raw data → manual rules → rulebook → predictions without data.",
        "C": "Contends that raw data → structured dataset with features/labels → learning algorithm → trained model/classifier used for predictions.",
        "D": "Posits that raw data → encryption → storage with no modelling."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "The pipeline comprises collecting raw data, structuring it into features with labels, applying a learning algorithm to derive a model (hypothesis), and deploying the model for classification or prediction. This workflow underpins the spam detection example and general ML practice.",
        "incorrect": {
          "A": "The sequence begins with raw data, not pre-structured data.",
          "B": "Machine learning relies on data-driven models, not manual rulebooks.",
          "C": "This is the correct answer.",
          "D": "Encryption/storage alone does not produce predictive models."
        },
        "reference": "Supervised ML Workflow - Raw Data → Structured Dataset → Learning Algorithm → Trained Model"
      }
    },
    {
      "id": "CLK-LT-M4-Q019",
      "question": "What is gradient descent and why is it central to machine learning, according to the notes?",
      "options": {
        "A": "Argues that an optimisation technique that iteratively adjusts model parameters to minimise a chosen loss function, enabling models to fit data even in high-dimensional spaces.",
        "B": "Maintains that a process of manually coding new rules into an expert system.",
        "C": "Contends that a data cleaning procedure for removing outliers.",
        "D": "Posits that a method for encrypting model weights."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "Gradient descent evaluates how changes in parameters affect the model's performance (loss) and updates them to reduce error. This calculus-powered iteration lets ML models learn from data efficiently, underpinning everything from linear regression to deep neural networks.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "Hand-coding rules belongs to symbolic AI, not gradient descent.",
          "C": "Outlier removal is distinct from optimisation.",
          "D": "Gradient descent optimises parameters; it does not encrypt them."
        },
        "reference": "Gradient Descent - Iterative Optimisation Minimising Loss Function; Core of ML Training"
      }
    },
    {
      "id": "CLK-LT-M4-Q020",
      "question": "How do large language models (LLMs) relate to the notion that generative AI is a subset of predictive AI?",
      "options": {
        "A": "Argues that lLMs randomly generate text without reference to prediction.",
        "B": "Maintains that lLMs operate solely on rule-based logic without statistical learning.",
        "C": "Contends that lLMs only classify documents and cannot generate text.",
        "D": "Posits that lLMs predict the next word (or token) based on prior context by chaining predictions, they generate coherent sentences, making generative output an extension of predictive modelling."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "The notes explain that a language model is trained to fill in missing words—essentially a predictive task. Generative capabilities arise by repeatedly applying these predictions: given sentence 1, predict sentence 2, and so on. Thus, generative AI leverages predictive modelling at scale.",
        "incorrect": {
          "A": "LLMs base their outputs on probabilistic prediction, not randomness.",
          "B": "LLMs rely on statistical learning, not hand-crafted rules.",
          "C": "LLMs both classify and generate; generation is a core function.",
          "D": "This is the correct answer."
        },
        "reference": "Generative AI as Predictive - LLMs Predict Next Tokens to Generate Text"
      }
    },
    {
      "id": "CLK-LT-M4-Q021",
      "question": "What does the notes' statement that 'all machine learners/neural networks/LLMs are matrix multiplications' emphasise?",
      "options": {
        "A": "Argues that that AI systems are mystical entities beyond mathematics.",
        "B": "Maintains that that despite anthropomorphic metaphors, these systems are ultimately numerical operations—parameters are numbers computed from data, and neurons are equations combining those numbers.",
        "C": "Contends that that AI operates without any data inputs.",
        "D": "Posits that that AI systems rely exclusively on symbolic logic."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "The remark demystifies AI: however impressive the outputs, the machinery consists of matrix operations adjusting numeric parameters. Recognising this counters anthropomorphic narratives and grounds legal analysis in the system's statistical nature.",
        "incorrect": {
          "A": "The notes reject mystical characterisations.",
          "B": "This is the correct answer.",
          "C": "Data drives parameter updates; AI is not data-free.",
          "D": "Neural networks are statistical, not purely symbolic."
        },
        "reference": "AI Mechanics - Matrix Multiplication View Highlights Statistical Nature of Models"
      }
    },
    {
      "id": "CLK-LT-M4-Q022",
      "question": "What is 'dispositionism' and how does it influence legal thinking about AI?",
      "options": {
        "A": "Argues that dispositionism treats technology as purely situational phenomena with no agency.",
        "B": "Maintains that dispositionism focuses exclusively on hardware specifications.",
        "C": "Contends that dispositionism assumes actors possess stable internal motives applied to AI, it leads us to personify systems (seeing wants, intentions) rather than examining situational factors like training data, designers, and operators.",
        "D": "Posits that dispositionism is the view that AI can never cause harm."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "Jerrold notes that law often attributes agency to actors based on presumed dispositions. When extended to AI, this bias encourages us to treat models as autonomous beings instead of scrutinising the human and organisational context shaping their outputs, potentially leading to misplaced liability debates (e.g., AI personality arguments).",
        "incorrect": {
          "A": "Dispositionism emphasises internal motives, not situational analysis.",
          "B": "Hardware details are secondary; the focus is on inferred agency.",
          "C": "This is the correct answer.",
          "D": "Dispositionism does not claim AI is harmless."
        },
        "reference": "Dispositionism - Bias Toward Attributing AI Intentions; Risks Personifying Statistical Systems"
      }
    },
    {
      "id": "CLK-LT-M4-Q023",
      "question": "What is the 'missing person problem' in AI law?",
      "options": {
        "A": "Argues that the concern that when AI performs tasks traditionally done by humans, legal frameworks struggle to identify responsible persons, prompting calls (sometimes misguided) for AI personality.",
        "B": "Maintains that a shortage of AI engineers in the workforce.",
        "C": "Contends that the problem of AI failing to recognise faces.",
        "D": "Posits that a data privacy issue relating to identity theft."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "As AI systems assume roles once filled by human agents, some commentators argue that legal responsibility 'disappears.' Jerrold critiques this framing, urging us to look at the surrounding human stakeholders rather than inventing AI legal personalities.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "The problem is conceptual, not workforce related.",
          "C": "Facial recognition is separate from the legal accountability debate.",
          "D": "The issue concerns liability attribution, not identity theft."
        },
        "reference": "Missing Person Problem - AI Replaces Human Actor, Prompting Debates on Responsibility Allocation"
      }
    },
    {
      "id": "CLK-LT-M4-Q024",
      "question": "What was the DABUS litigation used to illustrate in the notes?",
      "options": {
        "A": "Argues that that courts unanimously accept AI as inventors.",
        "B": "Maintains that that patent law has already fully embraced AI inventorship.",
        "C": "Contends that that AI cannot generate any creative output.",
        "D": "Posits that that dispositionist narratives can lead to claims that AI systems perceive, think, and feel like persons, pressing for legal recognition despite questionable factual autonomy most courts ultimately rejected these claims."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "Jerrold uses DABUS to show how anthropomorphic descriptions ('AI perceives like a person') push legal arguments for AI personhood. Senior courts largely resisted this, underscoring the importance of scrutinising the factual basis for autonomy claims.",
        "incorrect": {
          "A": "Courts in most jurisdictions rejected AI inventorship.",
          "B": "Patent law has not embraced AI inventorship broadly.",
          "C": "The debate was not about AI's ability to produce outputs but about legal attribution.",
          "D": "This is the correct answer."
        },
        "reference": "DABUS Case - Illustrates Dispositionist Pressures; Courts Mostly Rejected AI Inventorship"
      }
    },
    {
      "id": "CLK-LT-M4-Q025",
      "question": "What does Jerrold recommend regarding anthropomorphic AI narratives?",
      "options": {
        "A": "Argues that embrace them because they simplify legal decision-making.",
        "B": "Maintains that question and scrutinise anthropomorphisms embedded in descriptions (e g.",
        "C": "Contends that ignore all narratives and regulate AI randomly.",
        "D": "Posits that adopt AI personality statutes immediately."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "Jerrold warns that metaphors personifying AI can enslave legal thought (echoing Cardozo). Lawyers should interrogate language that implies AI dispositions, ensuring accountability focuses on situational stakeholders and technical realities.",
        "incorrect": {
          "A": "Jerrold cautions against uncritical adoption.",
          "B": "This is the correct answer.",
          "C": "Random regulation is not advocated; careful analysis is.",
          "D": "He opposes premature AI personhood absent factual autonomy."
        },
        "reference": "Jerrold's Guidance - Scrutinise Anthropomorphic Narratives to Avoid Misplaced Liability"
      }
    },
    {
      "id": "CLK-LT-M4-Q026",
      "question": "Why does Jerrold urge highlighting situational AI risks?",
      "options": {
        "A": "Argues that to shift blame entirely onto the AI system.",
        "B": "Maintains that because AI systems never create any risk themselves.",
        "C": "Contends that to refocus attention on the network of stakeholders (developers, operators, regulators) that shape AI behaviour, countering the tendency to treat the AI as an autonomous actor and aiding in apportioning safety and compensatory obligations.",
        "D": "Posits that because highlighting risks will eliminate the need for regulation."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "Situationism emphasises context. By mapping the socio-technical ecosystem behind AI outputs, lawmakers can assign responsibility to the appropriate human actors, rather than attributing outcomes to a mythical AI disposition.",
        "incorrect": {
          "A": "The goal is the opposite—avoid blaming the AI alone.",
          "B": "AI systems can manifest risks, but analysis should locate the human causes.",
          "C": "This is the correct answer.",
          "D": "Risk analysis informs regulation; it does not obviate it."
        },
        "reference": "Highlight Situational Risks - Map Stakeholders to Allocate Responsibility Accurately"
      }
    },
    {
      "id": "CLK-LT-M4-Q027",
      "question": "How should stakeholders be assessed under Jerrold's situationist approach?",
      "options": {
        "A": "Argues that assess each stakeholder situationally, recognising overlapping contributions and avoiding the trap of simply replacing one dispositionist analysis with another.",
        "B": "Maintains that identify a single scapegoat and ignore all other contributors.",
        "C": "Contends that assume manufacturers bear all liability regardless of context.",
        "D": "Posits that allocate responsibility randomly to avoid bias."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "Jerrold cautions against using situationism merely to pinpoint a new target for traditional blame. Instead, responsibility should reflect the interactions among developers, deployers, regulators, and users, encouraging nuanced risk allocation and governance structures.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "The aim is comprehensive, not scapegoating.",
          "C": "No single stakeholder is automatically liable; analysis must be contextual.",
          "D": "Random allocation undermines accountability."
        },
        "reference": "Assess Stakeholders Situationally - Distribute Responsibility Reflecting Socio-Technical Contributions"
      }
    },
    {
      "id": "CLK-LT-M4-Q028",
      "question": "What market incentives contribute to misunderstanding AI, according to the notes?",
      "options": {
        "A": "Argues that no incentives exist misunderstandings are purely accidental.",
        "B": "Maintains that regulators provide subsidies for understated AI marketing.",
        "C": "Contends that developers make more money when they explain AI accurately.",
        "D": "Posits that investors reward claims of 'thinking machines' more than frank descriptions of statistical software, and actors may deflect liability by blaming 'the AI,' encouraging exaggerated narratives."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "The notes point out that hype attracts investment, while anthropomorphic narratives can shift blame ('the AI did it'). These incentives perpetuate misunderstanding and demand critical scrutiny from lawyers and policymakers.",
        "incorrect": {
          "A": "The notes explicitly identify incentives.",
          "B": "No such subsidy is mentioned.",
          "C": "Honesty may not be rewarded; hype often is.",
          "D": "This is the correct answer."
        },
        "reference": "Market Incentives - Hype and Liability Deflection Encourage AI Misunderstandings"
      }
    },
    {
      "id": "CLK-LT-M4-Q029",
      "question": "Why does the notes caution that metaphors in law ‘must be narrowly watched’?",
      "options": {
        "A": "Argues that because metaphors are banned in legal writing.",
        "B": "Maintains that because metaphors that personify AI can shift legal outcomes, as Cardozo warned—initially useful analogies may later constrain thinking if taken too literally.",
        "C": "Contends that because metaphors provide precise mathematical definitions.",
        "D": "Posits that because metaphors guarantee objective decisions."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "Quoting Cardozo, the notes remind lawyers that metaphors can ossify into misleading doctrines. Anthropomorphic language about AI risks steering courts toward treating statistical systems as autonomous entities, distorting liability frameworks.",
        "incorrect": {
          "A": "Metaphors are common but must be used carefully.",
          "B": "This is the correct answer.",
          "C": "Metaphors are illustrative, not precise definitions.",
          "D": "Metaphors can, rather than guarantee objectivity, mislead analysis."
        },
        "reference": "Metaphors in AI Law - Cardozo’s Warning; Avoid Enslaving Legal Thought with Anthropomorphic Analogies"
      }
    },
    {
      "id": "CLK-LT-M4-Q030",
      "question": "Why does the notes say 'not regulating the AI itself (i.e. the math), but how it is used by people'?",
      "options": {
        "A": "Argues that because mathematics cannot be described or understood.",
        "B": "Maintains that because regulators refuse to understand statistics.",
        "C": "Contends that because AI models are mathematical tools risk arises from human deployment contexts (training data, oversight, use cases), so regulation should target usage, accountability, and governance rather than forbidding mathematical techniques per se.",
        "D": "Posits that because AI operates without any human involvement."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "The notes emphasise that AI frameworks are statistical engines. The law should focus on how humans build, train, and apply these tools—setting standards for responsibility, transparency, and oversight—rather than attempting to ban or anthropomorphise the underlying mathematics.",
        "incorrect": {
          "A": "Mathematics is understandable; the point is about regulatory focus.",
          "B": "The challenge is not regulator incompetence but appropriate targeting of rules.",
          "C": "This is the correct answer.",
          "D": "Humans play central roles in designing and using AI."
        },
        "reference": "Regulatory Focus - Govern Human Use of AI Tools Rather Than the Mathematical Mechanism Itself"
      }
    },
    {
      "id": "CLK-LT-M4-Q031",
      "question": "How did Alan Turing propose evaluating AI in 1950, and why is the question 'can machines think?' considered unhelpful in the notes?",
      "options": {
        "A": "Argues that he proposed the imitation game (Turing Test), focusing on whether a human can distinguish machine responses debating 'machines thinking' is unhelpful because 'machine' and 'think' are ill-defined.",
        "B": "Maintains that he proposed a hardware benchmark, and the question is unhelpful because hardware has not advanced.",
        "C": "Contends that he proposed measuring power consumption, and the question is unhelpful because machines already think like humans.",
        "D": "Posits that he proposed granting machines legal personhood, making the question obsolete."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "Turing reframed the discussion by suggesting a behavioural test (the imitation game) rather than philosophical debates about machine consciousness. The notes adopt this pragmatic stance, noting that definitional debates over 'thinking' hinder progress.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "Turing's test was conversational, not hardware-based.",
          "C": "Power consumption was not his metric.",
          "D": "Legal personhood was not part of Turing's proposal."
        },
        "reference": "Turing Test - Behavioural Evaluation; 'Can Machines Think?' Deemed Unhelpful"
      }
    },
    {
      "id": "CLK-LT-M4-Q032",
      "question": "Which categories from Russell and Norvig's textbook does the notes reference to define AI?",
      "options": {
        "A": "Argues that thinking symbolically, acting symbolically, thinking numerically, acting numerically.",
        "B": "Maintains that thinking legally, acting legally, thinking economically, acting economically.",
        "C": "Contends that thinking emotionally, acting emotionally, thinking instinctively, acting instinctively.",
        "D": "Posits that thinking humanly, thinking rationally, acting humanly, acting rationally."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "The notes reproduce Russell and Norvig's four-fold taxonomy: thinking humanly/rationally and acting humanly/rationally. These categories capture different research goals and evaluation metrics in AI.",
        "incorrect": {
          "A": "Symbolic/numerical acting categories were not highlighted.",
          "B": "These categories are not in the notes.",
          "C": "Emotional/instinctive distinctions were not discussed.",
          "D": "This is the correct answer."
        },
        "reference": "Russell & Norvig Taxonomy - Thinking vs Acting; Human vs Rational"
      }
    },
    {
      "id": "CLK-LT-M4-Q033",
      "question": "Why did the notes observe that the spam-classification example can be more explainable than a human decision?",
      "options": {
        "A": "Argues that because machine learning models never make mistakes.",
        "B": "Maintains that because the learned weights in a simple model (e g.",
        "C": "Contends that because humans cannot classify emails at all.",
        "D": "Posits that because machine learning relies solely on randomness."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "In linear models, feature weights make reasoning transparent: we can see how strongly 'lottery' or 'typos' influence the spam score. Human judgments often lack such clear articulation, underscoring ML's potential for consistent, auditable decisions in narrow tasks.",
        "incorrect": {
          "A": "Models can err; the point is about transparency, not infallibility.",
          "B": "This is the correct answer.",
          "C": "Humans can classify emails, but explanations may be vague.",
          "D": "Machine learning leverages learned patterns, not pure randomness."
        },
        "reference": "Spam Example - Feature Weights Provide Explainability Compared to Human Heuristics"
      }
    },
    {
      "id": "CLK-LT-M4-Q034",
      "question": "What is the fundamental attribution error discussed in the notes, and how does it relate to AI?",
      "options": {
        "A": "Argues that it is a computational bug in neural networks that prevents training.",
        "B": "Maintains that it is the legal rule that AI must always be liable for its outputs.",
        "C": "Contends that it is the human bias of over-attributing behaviour to internal dispositions rather than situational factors in AI, it leads us to blame or credit the system instead of the surrounding socio-technical context.",
        "D": "Posits that it is a requirement that AI training data exclude human behaviour."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "Psychology shows humans often overlook situational influences. Applied to AI, this bias encourages misplaced agency attribution to the system itself, obscuring responsible human actors. Recognising the error supports Jerrold's call for situationist analysis.",
        "incorrect": {
          "A": "The error is cognitive, not computational.",
          "B": "No such legal rule exists.",
          "C": "This is the correct answer.",
          "D": "Training data commonly includes human behaviour."
        },
        "reference": "Fundamental Attribution Error - Over-Attributing to AI Disposition; Need Situational Analysis"
      }
    },
    {
      "id": "CLK-LT-M4-Q035",
      "question": "Why does the notes claim that 'AI is by definition a human imitation game' and what consequence follows?",
      "options": {
        "A": "Argues that because AI systems are designed to emulate human outputs, making it easy for observers to be fooled therefore, narratives about autonomous AI must be scrutinised for hype and misplaced liability.",
        "B": "Maintains that because AI literally becomes human once deployed, so law should grant it rights.",
        "C": "Contends that because AI cannot imitate human behaviour at all.",
        "D": "Posits that because AI always replaces humans without any oversight."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "AI's goal of mimicking human performance makes anthropomorphic interpretations tempting. The notes warn that being impressed or deceived by this imitation should not lead to attributing agency the system lacks, reinforcing cautious legal analysis.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "The notes caution against equating AI with humans.",
          "C": "AI can imitate human-like outputs.",
          "D": "Human oversight remains pivotal; AI does not automatically replace humans."
        },
        "reference": "AI as Imitation Game - Susceptibility to Hype; Need for Critical Liability Assessment"
      }
    },
    {
      "id": "CLK-LT-M4-Q036",
      "question": "What does the remark that 'few have the technical training to properly understand, and even fewer actually want to know' imply for AI governance?",
      "options": {
        "A": "Argues that that only engineers should regulate AI.",
        "B": "Maintains that that legal education should exclude technology topics.",
        "C": "Contends that that AI systems require no regulation because nobody understands them.",
        "D": "Posits that that knowledge gaps exacerbate susceptibility to hype and anthropomorphism, necessitating deliberate efforts by lawyers and policymakers to build technical literacy and question simplistic narratives."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "Jerrold observes that limited technical literacy allows exaggerated claims to flourish. Effective governance demands intentional learning and scepticism from legal professionals to avoid being misled by marketing or sci-fi imagery.",
        "incorrect": {
          "A": "Multidisciplinary collaboration is preferable to narrow control.",
          "B": "The notes advocate the opposite—integrating tech understanding into legal discourse.",
          "C": "Ignorance heightens the need for informed regulation, not neglect.",
          "D": "This is the correct answer."
        },
        "reference": "Technical Literacy Gap - Encourages Hype; Lawyers Must Seek Understanding for Sound Governance"
      }
    },
    {
      "id": "CLK-LT-M4-Q037",
      "question": "Why does the notes mention that generative AI has been used since the 1990s?",
      "options": {
        "A": "Argues that to show that modern models lack any innovation.",
        "B": "Maintains that to contextualise current hype, noting that generative techniques (predictive text, language modelling) have a long history today's breakthroughs are scale and compute, not the mere existence of generative methods.",
        "C": "Contends that to argue that generative AI is obsolete.",
        "D": "Posits that to claim that only legacy systems can generate text."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "The note tempers novelty narratives, reminding readers that the concept of generative modelling predates recent LLMs. Recognising continuity helps avoid inflated claims about unprecedented capabilities warranting radical legal changes.",
        "incorrect": {
          "A": "There are significant innovations, particularly in scale.",
          "B": "This is the correct answer.",
          "C": "Generative AI remains highly relevant.",
          "D": "Modern systems extend, not replace, earlier techniques."
        },
        "reference": "Historical Context - Generative AI Roots in 1990s; Current Advances Lie in Scale"
      }
    },
    {
      "id": "CLK-LT-M4-Q038",
      "question": "What does the note suggest about the meaning of terms like 'neurons', 'attention', and 'memory' in AI systems?",
      "options": {
        "A": "Argues that that they literally replicate biological brains.",
        "B": "Maintains that that they refer to legal doctrines about AI liability.",
        "C": "Contends that that they are metaphors for mathematical operations (weighted sums, focus mechanisms, recurrent connections) and should not be mistaken for human cognitive processes.",
        "D": "Posits that that they represent emotional states within AI."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "These terms originate from analogies but correspond to specific computational constructs. Recognising their metaphorical nature prevents over-attributing human-like capacities to AI, aligning with Jerrold's caution against anthropomorphism.",
        "incorrect": {
          "A": "The notes warn against assuming biological equivalence.",
          "B": "They describe model architecture, not legal doctrines.",
          "C": "This is the correct answer.",
          "D": "They do not denote emotions."
        },
        "reference": "Metaphorical Terminology - 'Neurons', 'Attention', 'Memory' Represent Mathematical Operations"
      }
    },
    {
      "id": "CLK-LT-M4-Q039",
      "question": "What legal risk does personifying AI pose, as discussed in the notes?",
      "options": {
        "A": "Argues that it can shift focus away from human stakeholders, leading to misguided calls for AI personality or exemptions that obscure accountability.",
        "B": "Maintains that it ensures more accurate liability outcomes.",
        "C": "Contends that it reduces hype and encourages transparency.",
        "D": "Posits that it automatically increases consumer protection."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "By attributing agency to AI, legal debates may neglect the designers, operators, and regulators responsible for outcomes. Jerrold warns that this can precipitate ill-conceived reforms (e.g., AI legal personhood) that complicate accountability.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "Misplaced personification risks inaccurate outcomes.",
          "C": "Personification tends to fuel hype, not reduce it.",
          "D": "It can weaken consumer protection by deflecting responsibility."
        },
        "reference": "Risk of Personifying AI - Obscures Human Accountability; Leads to Problematic Legal Proposals"
      }
    },
    {
      "id": "CLK-LT-M4-Q040",
      "question": "How does Jerrold's situationist view propose handling safety and compensatory obligations in AI systems?",
      "options": {
        "A": "Argues that by attributing all responsibility to the AI itself.",
        "B": "Maintains that by holding only data subjects responsible for outcomes.",
        "C": "Contends that by abolishing liability altogether to encourage innovation.",
        "D": "Posits that by apportioning obligations across multiple stakeholders (developers, deployers, regulators, users) reflecting their situational contributions to risk."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "Jerrold argues that AI risks arise from socio-technical ecosystems. Effective governance distributes safety obligations and compensation duties to the parties who design, train, deploy, or oversee systems, aligning accountability with actual influence.",
        "incorrect": {
          "A": "Blaming the AI sidesteps real decision-makers.",
          "B": "Data subjects are typically victims, not cause of AI behaviour.",
          "C": "Liability is necessary to incentivise responsible conduct.",
          "D": "This is the correct answer."
        },
        "reference": "Situationist Allocation - Distribute Responsibilities Among Stakeholders According to Their Role"
      }
    },
    {
      "id": "CLK-LT-M4-Q041",
      "question": "How do public and private keys function in blockchain transactions, according to the notes?",
      "options": {
        "A": "Argues that the private key encrypts messages and the public key decrypts them, making communication public.",
        "B": "Maintains that the public key is shared so others can encrypt messages or verify signatures, while the private key remains secret and is used to decrypt or sign transactions, proving ownership.",
        "C": "Contends that both keys are publicly shared to maximise transparency.",
        "D": "Posits that keys are irrelevant because blockchain transactions are anonymous by default."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "Public-key cryptography enables confidentiality and authentication: senders encrypt using the recipient's public key (only the private key can decrypt) and holders sign transactions with their private key so anyone with the public key can verify authenticity.",
        "incorrect": {
          "A": "The direction is reversed; private keys are kept secret.",
          "B": "This is the correct answer.",
          "C": "Exposing private keys would compromise security.",
          "D": "Key pairs underpin blockchain ownership and signature schemes."
        },
        "reference": "Public/Private Keys - Public Key Shared for Encryption/Verification; Private Key Used for Decryption/Signing"
      }
    },
    {
      "id": "CLK-LT-M4-Q042",
      "question": "What are smart contracts as described in the notes?",
      "options": {
        "A": "Argues that traditional paper contracts stored on blockchain for safekeeping.",
        "B": "Maintains that legal agreements enforced exclusively by courts.",
        "C": "Contends that self-executing code with programmed conditions (e g.",
        "D": "Posits that contracts that require human approval before any step executes."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "Smart contracts embed obligations as code. When conditions (often data-driven) are satisfied, the contract executes automatically on-chain, reducing reliance on manual enforcement.",
        "incorrect": {
          "A": "They are executable code, not mere storage of PDFs.",
          "B": "Smart contracts seek to automate enforcement beyond court intervention.",
          "C": "This is the correct answer.",
          "D": "Their point is to reduce the need for human approval at execution time."
        },
        "reference": "Smart Contracts - Self-Executing Code with Programmable Conditions"
      }
    },
    {
      "id": "CLK-LT-M4-Q043",
      "question": "What other consensus mechanisms besides PoW and PoS does the notes mention, and what does this signify?",
      "options": {
        "A": "Argues that delegated Proof of Stake (DPoS) and Practical Byzantine Fault Tolerance (PBFT), indicating diverse approaches to achieving agreement beyond the two dominant models.",
        "B": "Maintains that only manual voting by regulators, showing blockchain cannot reach consensus autonomously.",
        "C": "Contends that there are no other mechanisms PoW is the only option.",
        "D": "Posits that quantum consensus, which relies on instant teleportation of transactions."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "The notes highlight DPoS and PBFT as alternative consensus designs, demonstrating ongoing innovation to balance security, efficiency, and decentralisation across different blockchain projects.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "Consensus mechanisms are algorithmic, not purely regulatory votes.",
          "C": "Multiple mechanisms exist beyond PoW.",
          "D": "Quantum consensus was not mentioned."
        },
        "reference": "Consensus Diversity - DPoS, PBFT Highlight Alternative Approaches"
      }
    },
    {
      "id": "CLK-LT-M4-Q044",
      "question": "What caution about data-driven models does the notes convey when stating that parameters reflect what the data says (and does not say)?",
      "options": {
        "A": "Argues that that parameters can be set arbitrarily without data.",
        "B": "Maintains that that models always override data with human intuition.",
        "C": "Contends that that parameters are meaningless numbers unrelated to outputs.",
        "D": "Posits that that model behaviour mirrors the training data's patterns and omissions, so biases or gaps in data propagate into AI decisions, underscoring the need for careful dataset curation and evaluation."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "The note warns that ML models learn precisely what is contained—and missing—in the data. Biased or incomplete datasets yield biased outputs, highlighting the importance of governance over data sourcing and evaluation.",
        "incorrect": {
          "A": "Parameters are learned from data, not set arbitrarily.",
          "B": "Models follow data-driven signals rather than intuition.",
          "C": "Parameters directly influence predictions.",
          "D": "This is the correct answer."
        },
        "reference": "Data Reflection - Model Parameters Encode Data Biases and Gaps"
      }
    },
    {
      "id": "CLK-LT-M4-Q045",
      "question": "What does the notes mean by saying 'learning is a metaphor for updating parameters'?",
      "options": {
        "A": "Argues that that AI systems literally gain consciousness when trained.",
        "B": "Maintains that that training consists of mathematical optimisation adjusting parameters to better fit data 'learning' anthropomorphises this process.",
        "C": "Contends that that AI training involves human teachers grading homework.",
        "D": "Posits that that learning requires no data or optimisation."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "The term 'learning' evokes human cognition, but in ML it refers to algorithmic parameter updates via optimisation methods (e.g., gradient descent). Recognising the metaphor prevents over-ascribing human traits to statistical processes.",
        "incorrect": {
          "A": "Training does not grant consciousness.",
          "B": "This is the correct answer.",
          "C": "Human grading is not part of typical ML training.",
          "D": "Data and optimisation are essential."
        },
        "reference": "Learning Metaphor - Parameter Optimisation, Not Human Cognition"
      }
    },
    {
      "id": "CLK-LT-M4-Q046",
      "question": "Why does the notes describe modern LLMs (e.g., GPT-3.5) as computationally expensive?",
      "options": {
        "A": "Argues that because they use outdated hardware from the 1990s.",
        "B": "Maintains that because they are hand-coded by lawyers.",
        "C": "Contends that because they contain hundreds of billions of parameters requiring immense compute and energy to train and run, highlighting resource and sustainability considerations.",
        "D": "Posits that because they only run on consumer laptops."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "Scale is a distinguishing feature of contemporary LLMs; training models with 175B parameters demands massive computational resources, raising questions about cost, access, and environmental impact.",
        "incorrect": {
          "A": "State-of-the-art hardware is used, not outdated equipment.",
          "B": "Development is handled by engineers and researchers.",
          "C": "This is the correct answer.",
          "D": "Such models typically require specialised infrastructure, not just laptops."
        },
        "reference": "LLM Scale - Hundreds of Billions of Parameters Demand Significant Compute"
      }
    },
    {
      "id": "CLK-LT-M4-Q047",
      "question": "What is the 'android fallacy' referenced in the notes?",
      "options": {
        "A": "Argues that the tendency to personify AI systems as if they possessed human characteristics, leading to analytical errors in legal reasoning.",
        "B": "Maintains that the belief that androids cannot legally exist.",
        "C": "Contends that a programming mistake in robotics firmware.",
        "D": "Posits that a doctrine requiring robots to obtain licences."
      },
      "correct_answer": "A",
      "explanation": {
        "correct": "The android fallacy describes the mistaken assumption that AI/robots have human-like agency or understanding. Recognising this fallacy helps lawyers avoid attributing moral or legal qualities to statistical models.",
        "incorrect": {
          "A": "This is the correct answer.",
          "B": "The fallacy concerns perception, not legal existence.",
          "C": "It is conceptual, not a software bug.",
          "D": "No such licensing doctrine exists."
        },
        "reference": "Android Fallacy - Personifying AI Leads to Analytical Errors"
      }
    },
    {
      "id": "CLK-LT-M4-Q048",
      "question": "How does Calo's observation about judges' metaphor choices relate to AI regulation?",
      "options": {
        "A": "Argues that metaphors have no impact on legal outcomes.",
        "B": "Maintains that calo argues that metaphors should be replaced with technical jargon.",
        "C": "Contends that judges avoid metaphors entirely when discussing technology.",
        "D": "Posits that judges' selection of metaphors or analogies for new technology can determine legal outcomes, so care must be taken to avoid metaphors that mischaracterise AI's nature."
      },
      "correct_answer": "D",
      "explanation": {
        "correct": "Calo highlights that metaphors frame the issues judges consider salient. Misleading analogies (e.g., calling AI a 'person') can steer doctrine in problematic directions, reinforcing Jerrold's warning about anthropomorphic narratives.",
        "incorrect": {
          "A": "Metaphors can significantly shape reasoning.",
          "B": "Calo does not call for jargon but for thoughtful metaphor use.",
          "C": "Judges frequently employ metaphors; the issue is choosing them wisely.",
          "D": "This is the correct answer."
        },
        "reference": "Calo on Metaphors - Judicial Analogies Influence AI Legal Outcomes"
      }
    },
    {
      "id": "CLK-LT-M4-Q049",
      "question": "Why are calls for AI personality symptomatic of dispositionism, according to the notes?",
      "options": {
        "A": "Argues that because AI already possesses legal rights that must be acknowledged.",
        "B": "Maintains that because attributing internal agency to AI (rather than examining situational factors) motivates proposals to grant AI legal personhood, despite lack of factual autonomy.",
        "C": "Contends that because dispositionism denies that humans contribute to AI behaviour.",
        "D": "Posits that because courts universally accept AI personhood."
      },
      "correct_answer": "B",
      "explanation": {
        "correct": "Dispositionism leads to viewing AI as an actor with intentions, prompting arguments for recognising AI as inventors or legal persons. Jerrold views these proposals as misplaced, urging focus on human stakeholders instead.",
        "incorrect": {
          "A": "AI does not currently hold broad legal rights.",
          "B": "This is the correct answer.",
          "C": "Dispositionism overemphasises internal agency, not deny human roles.",
          "D": "Courts largely reject AI personhood thus far."
        },
        "reference": "Calls for AI Personhood - Symptom of Dispositionism; Misplaces Responsibility"
      }
    },
    {
      "id": "CLK-LT-M4-Q050",
      "question": "What overarching takeaway does Jerrold offer for thinking about AI systems in law?",
      "options": {
        "A": "Argues that embrace anthropomorphic metaphors to simplify liability.",
        "B": "Maintains that treat AI as autonomous persons deserving legal rights.",
        "C": "Contends that scrutinise narratives, recognise AI as statistical tools situated within socio-technical ecosystems, and allocate responsibility among human stakeholders rather than the machine.",
        "D": "Posits that ignore AI regulation until courts grant it personhood."
      },
      "correct_answer": "C",
      "explanation": {
        "correct": "Jerrold's upshot is to move beyond dispositionist biases, interrogate metaphors, and adopt a situationist lens that keeps human actors at the centre of accountability for AI outcomes.",
        "incorrect": {
          "A": "He warns against uncritical reliance on metaphors.",
          "B": "He critiques proposals for AI personhood absent real autonomy.",
          "C": "This is the correct answer.",
          "D": "Proactive governance is urged, not delay."
        },
        "reference": "Jerrold's Takeaway - Treat AI as Statistical Tools; Focus on Human Accountability"
      }
    }
  ]
}
